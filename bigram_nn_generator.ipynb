{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'of', 'and', 'to', 'in', 'a', 'is', 'that', 'for', 'it']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"most_used_words.txt\") as file:\n",
    "    words = file.read().split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating input and output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838692"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "for word in words:\n",
    "    X.append(\".\")\n",
    "    Y.append(word[0])\n",
    "    for x, y in zip(word, word[1:]+\".\"):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". -> t\n",
      "t -> h\n",
      "h -> e\n",
      "e -> .\n",
      ". -> o\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(X[:5], Y):\n",
    "    print(x, \"->\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838692"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(\".\".join(words)))\n",
    "atoi = {a:i for i,a in enumerate(chars)}\n",
    "itoa = {i:a for i,a in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838692"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xi = torch.tensor(list(map(lambda x: atoi[x], X)))\n",
    "Yi = torch.tensor(list(map(lambda x: atoi[x], Y)))\n",
    "num = Xi.nelement()\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xenc = torch.nn.functional.one_hot(Xi, num_classes=27).float()\n",
    "g = torch.Generator().manual_seed(37469124)\n",
    "W = torch.randn((27,27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.691195011138916\n",
      "2.691195011138916\n",
      "2.691195011138916\n",
      "2.691195011138916\n",
      "2.691195011138916\n",
      "2.691195011138916\n",
      "2.691195011138916\n",
      "2.691195011138916\n",
      "2.691195011138916\n",
      "2.691195011138916\n"
     ]
    }
   ],
   "source": [
    "# Gradient decent\n",
    "for _ in range(100):\n",
    "    # Forward pass\n",
    "    B = (Xenc @ W).exp()\n",
    "    probs = B/B.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num), Yi].log().mean() + 0.1*(W**2).mean()\n",
    "    if _%10==0: print(loss.item())\n",
    "    # Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    # Update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lltondm.\n",
      "barcr.\n",
      "ccrnj.\n",
      "pi.\n",
      "doarrnchtesxaerrcrtnrnai.\n",
      "bobidiplbaevhponcsffjelielpgbu.\n",
      "tojepsmc.\n",
      "se.\n",
      "msc.\n",
      "bysrnp.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(37469124)\n",
    "ix = 0\n",
    "for _ in range(10):\n",
    "    while True:\n",
    "        prob = probs[ix]\n",
    "        ix = torch.multinomial(prob, num_samples=1, replacement=True, generator=g).item()\n",
    "        print(itoa[ix], end=\"\")\n",
    "        if(ix==0): break\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
